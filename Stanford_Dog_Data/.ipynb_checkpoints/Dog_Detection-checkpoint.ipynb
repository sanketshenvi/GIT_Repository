{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link:https://www.kaggle.com/twhitehurst3/stanford-dogs-keras-vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import argmax\n",
    "from __future__ import absolute_import, division, print_function\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import os\n",
    "from keras import layers\n",
    "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "import pydot\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "from keras.initializers import glorot_uniform\n",
    "import scipy.misc\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline\n",
    "from numpy import argmax\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "K.set_learning_phase(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_assignment(img,label):\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def training_data(label,data_dir):\n",
    "    for img in tqdm(os.listdir(data_dir)):\n",
    "        label = label_assignment(img,label)\n",
    "        path = os.path.join(data_dir,img)\n",
    "        img = cv2.imread(path,cv2.IMREAD_COLOR)\n",
    "        img = cv2.resize(img,(imgsize,imgsize))\n",
    "        X.append(np.array(img))\n",
    "        Z.append(str(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 152/152 [00:00<00:00, 240.62it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 185/185 [00:00<00:00, 336.58it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 252/252 [00:00<00:00, 294.44it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 149/149 [00:00<00:00, 300.50it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 214/214 [00:00<00:00, 281.13it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 188/188 [00:00<00:00, 267.47it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 196/196 [00:00<00:00, 294.48it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 172/172 [00:00<00:00, 277.69it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 239/239 [00:00<00:00, 256.44it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 175/175 [00:00<00:00, 245.13it/s]\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "Z = []\n",
    "imgsize = 150\n",
    "directory=\"C:/Users/Sanket.Shenvi/Desktop/Data Analytics/Deep_Learning/Stanford_Dog_Data/stanford-dogs-dataset/images/Images\"\n",
    "chihuahua_dir=directory+'/n02085620-Chihuahua'\n",
    "japanese_spaniel_dir = directory+'/n02085782-Japanese_spaniel'\n",
    "maltese_dir = directory+'/n02085936-Maltese_dog'\n",
    "pekinese_dir = directory+'/n02086079-Pekinese'\n",
    "shitzu_dir = directory+'/n02086240-Shih-Tzu'\n",
    "blenheim_spaniel_dir = directory+'/n02086646-Blenheim_spaniel'\n",
    "papillon_dir = directory+'/n02086910-papillon'\n",
    "toy_terrier_dir = directory+'/n02087046-toy_terrier'\n",
    "afghan_hound_dir = directory+'/n02088094-Afghan_hound'\n",
    "basset_dir = directory+'/n02088238-basset'\n",
    "\n",
    "\n",
    "training_data(\"chihuahua\",chihuahua_dir)\n",
    "training_data('japanese_spaniel',japanese_spaniel_dir)\n",
    "training_data('maltese',maltese_dir)\n",
    "training_data('pekinese',pekinese_dir)\n",
    "training_data('shitzu',shitzu_dir)\n",
    "training_data('blenheim_spaniel',blenheim_spaniel_dir)\n",
    "training_data('papillon',papillon_dir)\n",
    "training_data('toy_terrier',toy_terrier_dir)\n",
    "training_data('afghan_hound',afghan_hound_dir)\n",
    "training_data('basset',basset_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "Z = np.array(Z)\n",
    "n = np.arange(X.shape[0])\n",
    "np.random.shuffle(n)\n",
    "X=X[n]\n",
    "Z=Z[n]\n",
    "X = X.astype(np.float32)\n",
    "X=X/255\n",
    "le= LabelEncoder()\n",
    "Y = le.fit_transform(Z)\n",
    "Y = to_categorical(Y,10)\n",
    "X = np.array(X)\n",
    "X=X/255\n",
    "x_train,x_test,y_train,y_test = train_test_split(X,Y,test_size=0.3,random_state=69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############Decoding_Encoder##############\n",
    "#y_test=argmax(y_test,axis=0)\n",
    "#list(le.inverse_transform(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1345, 10)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
