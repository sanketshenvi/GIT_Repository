{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import scipy.misc\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "import seaborn as sns\n",
    "import keras\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras import backend\n",
    "from keras.models import Model\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from scipy.optimize import fmin_l_bfgs_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image(image_path,target_size):\n",
    "    img = load_img(image_path, target_size=target_size)\n",
    "    img=img_to_array(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_image_path=\"../input/dataset12/model2.jpg\"\n",
    "style_image_path=\"../input/dataset12/sketch.jpg\"\n",
    "target_size=(437,450)\n",
    "base_image=image(base_image_path,target_size)\n",
    "style_image=image(style_image_path,target_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Base image shape:{} and Style image shape:{}\".format(base_image.shape, style_image.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_image_plot = load_img(base_image_path, target_size=target_size)\n",
    "style_image_plot = load_img(style_image_path, target_size=target_size)\n",
    "fig=plt.figure(figsize=(7,7))\n",
    "ax=plt.subplot(1,2,1)\n",
    "ax.set_title(\"Base Image\")\n",
    "imshow(base_image_plot)\n",
    "ax1=plt.subplot(1,2,2)\n",
    "ax1.set_title(\"Style Image\")\n",
    "imshow(style_image_plot)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(img):\n",
    "    img = img.copy()                   \n",
    "    img = np.expand_dims(img, axis=0) \n",
    "    return keras.applications.vgg16.preprocess_input(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deprocess(img):\n",
    "    img = img.copy()                   \n",
    "    img = img[0]                        \n",
    "    img[:, :, 0] += 103.939           \n",
    "    img[:, :, 1] += 116.779             \n",
    "    img[:, :, 2] += 123.68             \n",
    "    img = img[:, :, ::-1]              \n",
    "    img = np.clip(img, 0, 255)         \n",
    "    return img.astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inputs(original_img, style_img):\n",
    "    original_input   = tf.constant(preprocess(original_img))\n",
    "    style_input     = tf.constant(preprocess(style_img))\n",
    "    generated_input = tf.placeholder(tf.float32, original_input.shape)\n",
    "    return original_input, style_input, generated_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_input, style_input, generated_input = inputs(base_image, style_image)\n",
    "input_tensor = tf.concat([original_input, style_input, generated_input], axis=0)\n",
    "input_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16_model = keras.applications.vgg16.VGG16(\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=input_tensor, \n",
    "    include_top=False)\n",
    "vgg16_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16_layer_dict = {layer.name:layer for layer in vgg16_model.layers}\n",
    "for key,val in vgg16_layer_dict.items():\n",
    "    print(\"{} => {}\".format(key,val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_original_loss(layer_dict, original_layer_names):\n",
    "    loss = 0\n",
    "    for name in original_layer_names:\n",
    "        layer = layer_dict[name]\n",
    "        original_features = layer.output[0, :, :, :]  \n",
    "        generated_features = layer.output[2, :, :, :] \n",
    "        loss += keras.backend.sum(keras.backend.square(generated_features - original_features))\n",
    "    return loss / len(original_layer_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gram_matrix(x):    \n",
    "    features = keras.backend.batch_flatten(keras.backend.permute_dimensions(x, (2, 0, 1))) \n",
    "    gram = keras.backend.dot(features, keras.backend.transpose(features))\n",
    "    return gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_style_loss(style_features, generated_features, size):\n",
    "    S = gram_matrix(style_features)\n",
    "    G = gram_matrix(generated_features)\n",
    "    channels = 3\n",
    "    return keras.backend.sum(keras.backend.square(S - G)) / (4. * (channels**2) * (size**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_style_loss(layer_dict, style_layer_names, size):\n",
    "    loss = 0\n",
    "    for name in style_layer_names:\n",
    "        layer = layer_dict[name]\n",
    "        style_features     = layer.output[1, :, :, :] \n",
    "        generated_features = layer.output[2, :, :, :] \n",
    "        loss += get_style_loss(style_features, generated_features, size) \n",
    "    return loss / len(style_layer_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_variation_loss(x):\n",
    "    row_diff = keras.backend.square(x[:, :-1, :-1, :] - x[:, 1:,    :-1, :])\n",
    "    col_diff = keras.backend.square(x[:, :-1, :-1, :] - x[:,  :-1, 1:,   :])\n",
    "    return keras.backend.sum(keras.backend.pow(row_diff + col_diff, 1.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_loss = calculate_original_loss(vgg16_layer_dict, ['block5_conv2'])\n",
    "style_layers = ['block1_conv1','block2_conv1','block3_conv1','block4_conv1', 'block5_conv1']\n",
    "style_loss = calculate_style_loss(vgg16_layer_dict, style_layers, \n",
    "                                  base_image.shape[0]*base_image.shape[1])\n",
    "variation_loss = calculate_variation_loss(generated_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "loss = 0.5 * original_loss + 1.0 * style_loss + 0.1 * variation_loss\n",
    "gradients = keras.backend.gradients(loss, generated_input)[0]\n",
    "calculate = keras.backend.function([generated_input], [loss, gradients])\n",
    "generated_data=preprocess(base_image)\n",
    "for i in tqdm(range(250)):\n",
    "    _, gradients_value = calculate([generated_data])\n",
    "    generated_data -= gradients_value * 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(10,10))\n",
    "ax=plt.subplot(1,3,1)\n",
    "ax.set_title(\"Base Image\")\n",
    "imshow(base_image_plot)\n",
    "ax1=plt.subplot(1,3,2)\n",
    "ax1.set_title(\"Style Image\")\n",
    "imshow(style_image_plot)\n",
    "\n",
    "\n",
    "generated_image01 = deprocess(generated_data)\n",
    "ax1=plt.subplot(1,3,3)\n",
    "ax1.set_title(\"Output Image\")\n",
    "imshow(cv2.cvtColor(generated_image01, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
